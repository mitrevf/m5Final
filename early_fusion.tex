\section{Early Fusion}
	\indent	In the second week of the project, we experimented with our setup for Bag of Words framework. We made changes to the method of selecting key points, played a bit with the parameters for the detector/descriptor and number of centroids k for the vocabulary, as well as early fusion of shape and color descriptors in order to produce a better result.
\par	As we already know, we collect key points from features on all images on the training set and then we randomly select predefined number of samples from that pool. For that parameter, we chose 50 000 samples. The issue there might be selecting a lot of points from some images, while other images are not represented in the training process (because the method is to randomly select from all the pool). Moreover, there is no rule to filter already selected points, which means that we can select the same point many times whereas others are left off. We tried to alternate the proposed method in such a way, it no longer selected key point randomly from the whole pool of points. Instead of randomly choosing an image, it iterates through the images and then randomly selects a feature. We believe that with that all the images in the dataset are equally represented, while key points are still selected randomly from the predetermined image in that particular iteration. We are unable to confirm that we improved our results with this technique, as they were really similar to the ones we achieved previously. However, we can say that he computational cost of this small change is insignificant.
\par	Here we also tried to fuse two different feature descriptors in an early fusion fashion â€“ fusion is performed before building the vocabulary. Essentially, it is concatenating the two histograms of both descriptors. We tested  and compared SIFT descriptor, the provided color descriptor and a fusion of both with different parameter for k-means, as shown below on the figure. We also tried fusing the color descriptor with SURF instead of SIFT, but it produced worse results. We observed that SIFT is a lot more effective descriptor than the color descriptor. While parameter k in our test varied, parameters C and number of pixels were fixed and set to 1 and 50000 respectively. We can conclude that early fusion really did help and improved the performances on the given dataset; as seen on the figure below, just with SIFT we got 80 \% accuracy and with early fusion between sift and the color descriptor we achieved the best result of \textbf{82.652 \%}, which is improvement of more than 2.5 \%. We recorded these results with linear SVM kernel for classification and 2000 centroids for k-means. 

\centerline{\includegraphics[scale=0.8]{figures/EF.png}}

\par	We should also note that for fusion of 2 different descriptors (in this case color and shape), data whitening (normalization) must be performed before the actual fusion process. That comes from the fact that every descriptor uses different values for describing the features and they are likely to be disproportional, hence the need for normalization.

